{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enade - Transformação de Dados - 01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para limpar o DataFrame\n",
    "def clean_dataset(df):\n",
    "    # Substituir valores infinitos por NaN\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    # Remover valores NaN\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Resetar o índice\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o diretório extraído\n",
    "data_dir = \"./enade2019/microdados_Enade_2019_LGPD/2. DADOS/\"\n",
    "\n",
    "# Lista para armazenar os DataFrames\n",
    "dataframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar todos os arquivos .txt no diretório de dados\n",
    "txt_files = [f for f in os.listdir(data_dir) if f.endswith('.txt')]\n",
    "\n",
    "# Ler todos os arquivos .txt e armazenar os DataFrames na lista\n",
    "for txt_file in txt_files:\n",
    "    # Obter o caminho completo do arquivo\n",
    "    file_path = os.path.join(data_dir, txt_file)\n",
    "    # Ler o arquivo como um DataFrame do Pandas, separando por ';' e usando ',' como decimal\n",
    "    df = pd.read_csv(file_path, sep=\";\", decimal=\",\", low_memory=False)\n",
    "    # Limpar o DataFrame\n",
    "    df = clean_dataset(df)\n",
    "    # Adicionar o DataFrame à lista\n",
    "    dataframes.append(df)\n",
    "    \n",
    "# Combinar todos os DataFrames em um único DataFrame\n",
    "enade = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_ANO</th>\n",
       "      <th>CO_CURSO</th>\n",
       "      <th>CO_IES</th>\n",
       "      <th>CO_CATEGAD</th>\n",
       "      <th>CO_ORGACAD</th>\n",
       "      <th>CO_GRUPO</th>\n",
       "      <th>CO_MODALIDADE</th>\n",
       "      <th>CO_MUNIC_CURSO</th>\n",
       "      <th>CO_UF_CURSO</th>\n",
       "      <th>CO_REGIAO_CURSO</th>\n",
       "      <th>...</th>\n",
       "      <th>QE_I64</th>\n",
       "      <th>QE_I65</th>\n",
       "      <th>QE_I66</th>\n",
       "      <th>QE_I67</th>\n",
       "      <th>QE_I68</th>\n",
       "      <th>TP_SEXO</th>\n",
       "      <th>NU_IDADE</th>\n",
       "      <th>QE_I01</th>\n",
       "      <th>QE_I02</th>\n",
       "      <th>QE_I03</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10028.0</td>\n",
       "      <td>5710.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5103403.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10028.0</td>\n",
       "      <td>5710.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5103403.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10028.0</td>\n",
       "      <td>5710.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5103403.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10028.0</td>\n",
       "      <td>5710.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5103403.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10028.0</td>\n",
       "      <td>5710.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5103403.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NU_ANO  CO_CURSO  CO_IES  CO_CATEGAD  CO_ORGACAD  CO_GRUPO  CO_MODALIDADE  \\\n",
       "0    2019         3     1.0         1.0     10028.0    5710.0            1.0   \n",
       "1    2019         3     1.0         1.0     10028.0    5710.0            1.0   \n",
       "2    2019         3     1.0         1.0     10028.0    5710.0            1.0   \n",
       "3    2019         3     1.0         1.0     10028.0    5710.0            1.0   \n",
       "4    2019         3     1.0         1.0     10028.0    5710.0            1.0   \n",
       "\n",
       "   CO_MUNIC_CURSO  CO_UF_CURSO  CO_REGIAO_CURSO  ... QE_I64 QE_I65 QE_I66  \\\n",
       "0       5103403.0         51.0              5.0  ...    NaN    NaN    NaN   \n",
       "1       5103403.0         51.0              5.0  ...    NaN    NaN    NaN   \n",
       "2       5103403.0         51.0              5.0  ...    NaN    NaN    NaN   \n",
       "3       5103403.0         51.0              5.0  ...    NaN    NaN    NaN   \n",
       "4       5103403.0         51.0              5.0  ...    NaN    NaN    NaN   \n",
       "\n",
       "  QE_I67 QE_I68 TP_SEXO NU_IDADE QE_I01 QE_I02 QE_I03  \n",
       "0    NaN    NaN     NaN      NaN    NaN    NaN    NaN  \n",
       "1    NaN    NaN     NaN      NaN    NaN    NaN    NaN  \n",
       "2    NaN    NaN     NaN      NaN    NaN    NaN    NaN  \n",
       "3    NaN    NaN     NaN      NaN    NaN    NaN    NaN  \n",
       "4    NaN    NaN     NaN      NaN    NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NU_ANO': dtype('int64'),\n",
       " 'CO_CURSO': dtype('int64'),\n",
       " 'CO_IES': dtype('float64'),\n",
       " 'CO_CATEGAD': dtype('float64'),\n",
       " 'CO_ORGACAD': dtype('float64'),\n",
       " 'CO_GRUPO': dtype('float64'),\n",
       " 'CO_MODALIDADE': dtype('float64'),\n",
       " 'CO_MUNIC_CURSO': dtype('float64'),\n",
       " 'CO_UF_CURSO': dtype('float64'),\n",
       " 'CO_REGIAO_CURSO': dtype('float64'),\n",
       " 'QE_I04': dtype('O'),\n",
       " 'QE_I05': dtype('O'),\n",
       " 'QE_I06': dtype('O'),\n",
       " 'QE_I07': dtype('O'),\n",
       " 'QE_I08': dtype('O'),\n",
       " 'QE_I09': dtype('O'),\n",
       " 'QE_I10': dtype('O'),\n",
       " 'QE_I11': dtype('O'),\n",
       " 'QE_I12': dtype('O'),\n",
       " 'QE_I13': dtype('O'),\n",
       " 'ANO_FIM_EM': dtype('float64'),\n",
       " 'ANO_IN_GRAD': dtype('float64'),\n",
       " 'CO_TURNO_GRADUACAO': dtype('float64'),\n",
       " 'QE_I14': dtype('O'),\n",
       " 'QE_I15': dtype('O'),\n",
       " 'QE_I16': dtype('float64'),\n",
       " 'QE_I17': dtype('O'),\n",
       " 'QE_I18': dtype('O'),\n",
       " 'QE_I19': dtype('O'),\n",
       " 'QE_I20': dtype('O'),\n",
       " 'QE_I21': dtype('O'),\n",
       " 'QE_I22': dtype('O'),\n",
       " 'QE_I23': dtype('O'),\n",
       " 'NU_ITEM_OFG': dtype('float64'),\n",
       " 'NU_ITEM_OFG_Z': dtype('float64'),\n",
       " 'NU_ITEM_OFG_X': dtype('float64'),\n",
       " 'NU_ITEM_OFG_N': dtype('float64'),\n",
       " 'NU_ITEM_OCE': dtype('float64'),\n",
       " 'NU_ITEM_OCE_Z': dtype('float64'),\n",
       " 'NU_ITEM_OCE_X': dtype('float64'),\n",
       " 'NU_ITEM_OCE_N': dtype('float64'),\n",
       " 'DS_VT_GAB_OFG_FIN': dtype('O'),\n",
       " 'DS_VT_GAB_OCE_FIN': dtype('O'),\n",
       " 'DS_VT_ESC_OFG': dtype('O'),\n",
       " 'DS_VT_ACE_OFG': dtype('float64'),\n",
       " 'DS_VT_ESC_OCE': dtype('O'),\n",
       " 'DS_VT_ACE_OCE': dtype('O'),\n",
       " 'TP_PRES': dtype('float64'),\n",
       " 'TP_PR_GER': dtype('float64'),\n",
       " 'TP_PR_OB_FG': dtype('float64'),\n",
       " 'TP_PR_DI_FG': dtype('float64'),\n",
       " 'TP_PR_OB_CE': dtype('float64'),\n",
       " 'TP_PR_DI_CE': dtype('float64'),\n",
       " 'TP_SFG_D1': dtype('float64'),\n",
       " 'TP_SFG_D2': dtype('float64'),\n",
       " 'TP_SCE_D1': dtype('float64'),\n",
       " 'TP_SCE_D2': dtype('float64'),\n",
       " 'TP_SCE_D3': dtype('float64'),\n",
       " 'NT_GER': dtype('O'),\n",
       " 'NT_FG': dtype('O'),\n",
       " 'NT_OBJ_FG': dtype('O'),\n",
       " 'NT_DIS_FG': dtype('O'),\n",
       " 'NT_FG_D1': dtype('float64'),\n",
       " 'NT_FG_D1_PT': dtype('float64'),\n",
       " 'NT_FG_D1_CT': dtype('float64'),\n",
       " 'NT_FG_D2': dtype('float64'),\n",
       " 'NT_FG_D2_PT': dtype('float64'),\n",
       " 'NT_FG_D2_CT': dtype('float64'),\n",
       " 'NT_CE': dtype('O'),\n",
       " 'NT_OBJ_CE': dtype('O'),\n",
       " 'NT_DIS_CE': dtype('O'),\n",
       " 'NT_CE_D1': dtype('O'),\n",
       " 'NT_CE_D2': dtype('float64'),\n",
       " 'NT_CE_D3': dtype('O'),\n",
       " 'CO_RS_I1': dtype('O'),\n",
       " 'CO_RS_I2': dtype('O'),\n",
       " 'CO_RS_I3': dtype('O'),\n",
       " 'CO_RS_I4': dtype('O'),\n",
       " 'CO_RS_I5': dtype('O'),\n",
       " 'CO_RS_I6': dtype('O'),\n",
       " 'CO_RS_I7': dtype('O'),\n",
       " 'CO_RS_I8': dtype('O'),\n",
       " 'CO_RS_I9': dtype('O'),\n",
       " 'QE_I24': dtype('O'),\n",
       " 'QE_I25': dtype('O'),\n",
       " 'QE_I26': dtype('O'),\n",
       " 'QE_I27': dtype('float64'),\n",
       " 'QE_I28': dtype('float64'),\n",
       " 'QE_I29': dtype('float64'),\n",
       " 'QE_I30': dtype('float64'),\n",
       " 'QE_I31': dtype('float64'),\n",
       " 'QE_I32': dtype('float64'),\n",
       " 'QE_I33': dtype('float64'),\n",
       " 'QE_I34': dtype('float64'),\n",
       " 'QE_I35': dtype('float64'),\n",
       " 'QE_I36': dtype('float64'),\n",
       " 'QE_I37': dtype('float64'),\n",
       " 'QE_I38': dtype('float64'),\n",
       " 'QE_I39': dtype('float64'),\n",
       " 'QE_I40': dtype('float64'),\n",
       " 'QE_I41': dtype('float64'),\n",
       " 'QE_I42': dtype('float64'),\n",
       " 'QE_I43': dtype('float64'),\n",
       " 'QE_I44': dtype('float64'),\n",
       " 'QE_I45': dtype('float64'),\n",
       " 'QE_I46': dtype('float64'),\n",
       " 'QE_I47': dtype('float64'),\n",
       " 'QE_I48': dtype('float64'),\n",
       " 'QE_I49': dtype('float64'),\n",
       " 'QE_I50': dtype('float64'),\n",
       " 'QE_I51': dtype('float64'),\n",
       " 'QE_I52': dtype('float64'),\n",
       " 'QE_I53': dtype('float64'),\n",
       " 'QE_I54': dtype('float64'),\n",
       " 'QE_I55': dtype('float64'),\n",
       " 'QE_I56': dtype('float64'),\n",
       " 'QE_I57': dtype('float64'),\n",
       " 'QE_I58': dtype('float64'),\n",
       " 'QE_I59': dtype('float64'),\n",
       " 'QE_I60': dtype('float64'),\n",
       " 'QE_I61': dtype('float64'),\n",
       " 'QE_I62': dtype('float64'),\n",
       " 'QE_I63': dtype('float64'),\n",
       " 'QE_I64': dtype('float64'),\n",
       " 'QE_I65': dtype('float64'),\n",
       " 'QE_I66': dtype('float64'),\n",
       " 'QE_I67': dtype('float64'),\n",
       " 'QE_I68': dtype('float64'),\n",
       " 'TP_SEXO': dtype('O'),\n",
       " 'NU_IDADE': dtype('float64'),\n",
       " 'QE_I01': dtype('O'),\n",
       " 'QE_I02': dtype('O'),\n",
       " 'QE_I03': dtype('O')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando o schema da tabela\n",
    "dict(enade.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Váriaveis que vamos utilizar: \n",
    "\n",
    "- CO_IES\n",
    "\n",
    "- CO_CATEGAD\n",
    "\n",
    "- CO_GRUPO\n",
    "\n",
    "- CO_MODALIDADE\n",
    "\n",
    "- CO_UF_CURSO\n",
    "\n",
    "- CO_REGIAO_CURSO\n",
    "\n",
    "- NU_IDADE\n",
    "\n",
    "- TP_SEXO\n",
    "\n",
    "- NT_GER\n",
    "\n",
    "- NT_FG\n",
    "\n",
    "- NT_CE\n",
    "\n",
    "Mais alguns itens do questionário do estudante: \n",
    "\n",
    "01: Estado Civil\n",
    "\n",
    "02: Cor ou raça\n",
    "\n",
    "04: Escolaridade do pai\n",
    "\n",
    "05: Escolaridade da mãe\n",
    "\n",
    "08: Renda Familiar\n",
    "\n",
    "10: Situação de trabalho\n",
    "\n",
    "11: Situação de bolsa\n",
    "\n",
    "14: Intercâmbio\n",
    "\n",
    "15: Cotas\n",
    "\n",
    "23: Horas de Estudo / semana\n",
    "\n",
    "25: Motivo de escolha do curso\n",
    "\n",
    "26: Motivo de escolha da IES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter as colunas para o tipo correto, se necessário\n",
    "# Tratar NaN antes de converter para int e preencher com 0\n",
    "if 'CO_REGIAO_CURSO' in enade.columns:\n",
    "    # Tratar NaN antes de converter\n",
    "    enade['CO_REGIAO_CURSO'] = pd.to_numeric(enade['CO_REGIAO_CURSO'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "# Converter para float e tratar NaN\n",
    "if 'NT_GER' in enade.columns:\n",
    "    enade['NT_GER'] = pd.to_numeric(enade['NT_GER'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    378812.000000\n",
       "mean         44.272119\n",
       "std          14.457398\n",
       "min           0.000000\n",
       "25%          33.400000\n",
       "50%          44.000000\n",
       "75%          54.900000\n",
       "max          93.000000\n",
       "Name: NT_GER, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analisar a coluna NT_GER\n",
    "enade.NT_GER.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12721096"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar o numero de nulos\n",
    "enade.NT_GER.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13099908, 133)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enade.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9710828503528421"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade Relativa De Nulos\n",
    "enade.NT_GER.isnull().sum() / enade.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 1, 3, 4, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando valores da variavel\n",
    "enade['CO_REGIAO_CURSO'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CO_REGIAO_CURSO\n",
       "0    12665978\n",
       "3      202505\n",
       "2       91742\n",
       "4       76788\n",
       "5       34192\n",
       "1       28703\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar quantos registros existem para cada valor de CO_REGIAO_CURSO\n",
    "enade['CO_REGIAO_CURSO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    0.0\n",
       "mean     NaN\n",
       "std      NaN\n",
       "min      NaN\n",
       "25%      NaN\n",
       "50%      NaN\n",
       "75%      NaN\n",
       "max      NaN\n",
       "Name: NT_GER, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrando a nota geral por região \n",
    "enade.loc[\n",
    "    enade.CO_REGIAO_CURSO == 2 \n",
    "].NT_GER.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros na região 2: 91742\n",
      "Número de NaNs em NT_GER para CO_REGIAO_CURSO == 2: 91742\n",
      "Total de registros com NT_GER para CO_REGIAO_CURSO == 2: 0\n",
      "Média de NT_GER para CO_REGIAO_CURSO == 2: 0\n"
     ]
    }
   ],
   "source": [
    "# Filtrando a nota geral por região 2 e contando NaNs\n",
    "filtro_regiao = enade[enade['CO_REGIAO_CURSO'] == 2]\n",
    "total_registros = len(filtro_regiao)\n",
    "nulos_nt_ger = filtro_regiao['NT_GER'].isna().sum()\n",
    "total_nt_ger = filtro_regiao['NT_GER'].notna().sum()\n",
    "soma_nt_ger = filtro_regiao['NT_GER'].sum()\n",
    "media_nt_ger = soma_nt_ger / total_nt_ger if total_nt_ger > 0 else 0\n",
    "\n",
    "print(f\"Total de registros na região 2: {total_registros}\")\n",
    "print(f\"Número de NaNs em NT_GER para CO_REGIAO_CURSO == 2: {nulos_nt_ger}\")\n",
    "print(f\"Total de registros com NT_GER para CO_REGIAO_CURSO == 2: {total_nt_ger}\")\n",
    "print(f\"Média de NT_GER para CO_REGIAO_CURSO == 2: {media_nt_ger}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CO_REGIAO_CURSO  NT_GER\n",
      "1294                2     NaN\n",
      "1295                2     NaN\n",
      "1296                2     NaN\n",
      "1297                2     NaN\n",
      "1298                2     NaN\n",
      "1299                2     NaN\n",
      "1300                2     NaN\n",
      "1301                2     NaN\n",
      "1302                2     NaN\n",
      "1303                2     NaN\n"
     ]
    }
   ],
   "source": [
    "# Exibir algumas linhas do DataFrame filtrado para a região 2\n",
    "print(filtro_regiao[['CO_REGIAO_CURSO', 'NT_GER']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1294   NaN\n",
      "1295   NaN\n",
      "1296   NaN\n",
      "1297   NaN\n",
      "1298   NaN\n",
      "1299   NaN\n",
      "1300   NaN\n",
      "1301   NaN\n",
      "1302   NaN\n",
      "1303   NaN\n",
      "Name: NT_GER, dtype: float64\n",
      "91742\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Verificar alguns valores originais de NT_GER para a região 2 antes da conversão\n",
    "original_nt_ger = enade.loc[enade['CO_REGIAO_CURSO'] == 2, 'NT_GER']\n",
    "print(original_nt_ger.head(10))\n",
    "print(original_nt_ger.isna().sum())\n",
    "print(original_nt_ger.notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CO_REGIAO_CURSO  NT_GER\n",
      "1294                2     NaN\n",
      "1295                2     NaN\n",
      "1296                2     NaN\n",
      "1297                2     NaN\n",
      "1298                2     NaN\n",
      "1299                2     NaN\n",
      "1300                2     NaN\n",
      "1301                2     NaN\n",
      "1302                2     NaN\n",
      "1303                2     NaN\n",
      "1294   NaN\n",
      "1295   NaN\n",
      "1296   NaN\n",
      "1297   NaN\n",
      "1298   NaN\n",
      "1299   NaN\n",
      "1300   NaN\n",
      "1301   NaN\n",
      "1302   NaN\n",
      "1303   NaN\n",
      "Name: NT_GER, dtype: float64\n",
      "Total de valores originais de NT_GER para a região 2: 91742\n",
      "Total de NaNs em valores originais de NT_GER para a região 2: 91742\n",
      "Total de valores não nulos de NT_GER para a região 2: 0\n"
     ]
    }
   ],
   "source": [
    "# Exibir algumas linhas do DataFrame filtrado para a região 2\n",
    "print(filtro_regiao[['CO_REGIAO_CURSO', 'NT_GER']].head(10))\n",
    "\n",
    "# Verificar alguns valores originais de NT_GER para a região 2 antes da conversão\n",
    "original_nt_ger = enade.loc[enade['CO_REGIAO_CURSO'] == 2, 'NT_GER']\n",
    "print(original_nt_ger.head(10))\n",
    "print(f\"Total de valores originais de NT_GER para a região 2: {len(original_nt_ger)}\")\n",
    "print(f\"Total de NaNs em valores originais de NT_GER para a região 2: {original_nt_ger.isna().sum()}\")\n",
    "print(f\"Total de valores não nulos de NT_GER para a região 2: {original_nt_ger.notna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição de NaNs em NT_GER por região:\n",
      "CO_REGIAO_CURSO\n",
      "0    12287166\n",
      "1       28703\n",
      "2       91742\n",
      "3      202505\n",
      "4       76788\n",
      "5       34192\n",
      "Name: NT_GER, dtype: int64\n",
      "\n",
      "Total de registros por região:\n",
      "CO_REGIAO_CURSO\n",
      "0    12665978\n",
      "3      202505\n",
      "2       91742\n",
      "4       76788\n",
      "5       34192\n",
      "1       28703\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentual de NaNs em NT_GER por região:\n",
      "CO_REGIAO_CURSO\n",
      "0     97.009216\n",
      "1    100.000000\n",
      "2    100.000000\n",
      "3    100.000000\n",
      "4    100.000000\n",
      "5    100.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Verificar a distribuição de NaNs em NT_GER para todas as regiões\n",
    "nulos_por_regiao = enade.groupby('CO_REGIAO_CURSO')['NT_GER'].apply(lambda x: x.isna().sum())\n",
    "total_por_regiao = enade['CO_REGIAO_CURSO'].value_counts()\n",
    "percentual_nulos_por_regiao = (nulos_por_regiao / total_por_regiao) * 100\n",
    "\n",
    "print(\"Distribuição de NaNs em NT_GER por região:\")\n",
    "print(nulos_por_regiao)\n",
    "print(\"\\nTotal de registros por região:\")\n",
    "print(total_por_regiao)\n",
    "print(\"\\nPercentual de NaNs em NT_GER por região:\")\n",
    "print(percentual_nulos_por_regiao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo microdados2019_arq1.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'CO_IES', 'CO_CATEGAD', 'CO_ORGACAD', 'CO_GRUPO',\n",
      "       'CO_MODALIDADE', 'CO_MUNIC_CURSO', 'CO_UF_CURSO', 'CO_REGIAO_CURSO'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq10.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I04'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq11.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I05'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq12.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I06'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq13.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I07'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq14.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I08'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq15.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I09'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq16.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I10'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq17.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I11'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq18.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I12'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq19.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I13'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq2.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'ANO_FIM_EM', 'ANO_IN_GRAD',\n",
      "       'CO_TURNO_GRADUACAO'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq20.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I14'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq21.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I15'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq22.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I16'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq23.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I17'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq24.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I18'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq25.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I19'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq26.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I20'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq27.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I21'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq28.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I22'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq29.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I23'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq3.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'NU_ITEM_OFG', 'NU_ITEM_OFG_Z', 'NU_ITEM_OFG_X',\n",
      "       'NU_ITEM_OFG_N', 'NU_ITEM_OCE', 'NU_ITEM_OCE_Z', 'NU_ITEM_OCE_X',\n",
      "       'NU_ITEM_OCE_N', 'DS_VT_GAB_OFG_FIN', 'DS_VT_GAB_OCE_FIN',\n",
      "       'DS_VT_ESC_OFG', 'DS_VT_ACE_OFG', 'DS_VT_ESC_OCE', 'DS_VT_ACE_OCE',\n",
      "       'TP_PRES', 'TP_PR_GER', 'TP_PR_OB_FG', 'TP_PR_DI_FG', 'TP_PR_OB_CE',\n",
      "       'TP_PR_DI_CE', 'TP_SFG_D1', 'TP_SFG_D2', 'TP_SCE_D1', 'TP_SCE_D2',\n",
      "       'TP_SCE_D3', 'NT_GER', 'NT_FG', 'NT_OBJ_FG', 'NT_DIS_FG', 'NT_FG_D1',\n",
      "       'NT_FG_D1_PT', 'NT_FG_D1_CT', 'NT_FG_D2', 'NT_FG_D2_PT', 'NT_FG_D2_CT',\n",
      "       'NT_CE', 'NT_OBJ_CE', 'NT_DIS_CE', 'NT_CE_D1', 'NT_CE_D2', 'NT_CE_D3',\n",
      "       'CO_RS_I1', 'CO_RS_I2', 'CO_RS_I3', 'CO_RS_I4', 'CO_RS_I5', 'CO_RS_I6',\n",
      "       'CO_RS_I7', 'CO_RS_I8', 'CO_RS_I9'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq30.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I24'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq31.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I25'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq32.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I26'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq4.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I27', 'QE_I28', 'QE_I29', 'QE_I30', 'QE_I31',\n",
      "       'QE_I32', 'QE_I33', 'QE_I34', 'QE_I35', 'QE_I36', 'QE_I37', 'QE_I38',\n",
      "       'QE_I39', 'QE_I40', 'QE_I41', 'QE_I42', 'QE_I43', 'QE_I44', 'QE_I45',\n",
      "       'QE_I46', 'QE_I47', 'QE_I48', 'QE_I49', 'QE_I50', 'QE_I51', 'QE_I52',\n",
      "       'QE_I53', 'QE_I54', 'QE_I55', 'QE_I56', 'QE_I57', 'QE_I58', 'QE_I59',\n",
      "       'QE_I60', 'QE_I61', 'QE_I62', 'QE_I63', 'QE_I64', 'QE_I65', 'QE_I66',\n",
      "       'QE_I67', 'QE_I68'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq5.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'TP_SEXO'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq6.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'NU_IDADE'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq7.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I01'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq8.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I02'], dtype='object')\n",
      "\n",
      "\n",
      "Arquivo microdados2019_arq9.txt:\n",
      "Index(['NU_ANO', 'CO_CURSO', 'QE_I03'], dtype='object')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar as colunas presentes em cada arquivo antes de concatenar\n",
    "for txt_file in txt_files:\n",
    "    file_path = os.path.join(data_dir, txt_file)\n",
    "    df = pd.read_csv(file_path, sep=\";\", decimal=\",\", nrows=0)\n",
    "    print(f\"Arquivo {txt_file}:\")\n",
    "    print(df.columns)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Combinar todos os DataFrames em um único DataFrame novamente\n",
    "enade = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo microdados2019_arq1.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq10.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq11.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq12.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq13.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq14.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq15.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq16.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq17.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq18.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq19.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq2.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq20.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq21.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq22.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq23.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq24.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq25.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq26.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq27.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq28.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq29.txt lido com 433930 registros.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvgam\\AppData\\Local\\Temp\\ipykernel_16256\\3546896665.py:5: DtypeWarning: Columns (12,14,15,27,28,29,30,37,38,39,40,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep=\";\", decimal=\",\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo microdados2019_arq3.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq30.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq31.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq32.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq4.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq5.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq6.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq7.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq8.txt lido com 433930 registros.\n",
      "Arquivo microdados2019_arq9.txt lido com 433930 registros.\n",
      "\n",
      "Total de registros em todos os arquivos antes da concatenação: 13885760\n",
      "Total de registros após a concatenação: 13099908\n"
     ]
    }
   ],
   "source": [
    "# Verificar o número de registros em cada arquivo antes da concatenação\n",
    "total_registros_antes = 0\n",
    "for txt_file in txt_files:\n",
    "    file_path = os.path.join(data_dir, txt_file)\n",
    "    df = pd.read_csv(file_path, sep=\";\", decimal=\",\")\n",
    "    total_registros_antes += len(df)\n",
    "    print(f\"Arquivo {txt_file} lido com {len(df)} registros.\")\n",
    "\n",
    "# Verificar o número total de registros após a concatenação\n",
    "print(f\"\\nTotal de registros em todos os arquivos antes da concatenação: {total_registros_antes}\")\n",
    "print(f\"Total de registros após a concatenação: {len(enade)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
